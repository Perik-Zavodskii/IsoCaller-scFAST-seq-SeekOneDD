{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb89841d-c67c-467b-9548-65dc12f97b54",
   "metadata": {},
   "source": [
    "# Iso-Caller for scFASTseq data via Salmon-Alevin\n",
    "#### This pipeline should be run AFTER the regular seeksoultools fast run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5224ba8-b6a9-4388-b252-164c2df6fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "import json\n",
    "import subprocess\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Timestamp for logging\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Pipeline initialized.\")\n",
    "print(f\"Python Version: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732ee3e-5ddd-440e-8014-b170f7e31aa0",
   "metadata": {},
   "source": [
    "## Ref links:\n",
    "#### https://ftp.ensembl.org/pub/release-115/fasta/mus_musculus/cdna/ - cDNA Mus_musculus.GRCm39.cdna.all.fa.gz\n",
    "#### https://app.flow.bio/data/657359233329314859/ - Mus_musculus.GRCm39.109.sorted.gtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f3691-15f0-4fb1-bac4-0a897f1ff87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "\n",
    "# 1. Input Data (Raw FASTQ files)\n",
    "FASTQ_R1 = 'path/to/FASTQ_R1.fastq.gz'\n",
    "FASTQ_R2 = 'path/to/FASTQ_R2.fastq.gz'\n",
    "\n",
    "matrix_type = 'filtered' # raw / filtered\n",
    "\n",
    "# 2. Outpit directory\n",
    "OUTPUT_ROOT = f\"./Experiment_Isoform_{matrix_type}\"\n",
    "\n",
    "# 3. Reference Genome Assets\n",
    "# cDNA FASTA is required for index building and tgMap generation\n",
    "REF_FASTA = './iso_ref/Mus_musculus.GRCm39.cdna.all.fa.gz'\n",
    "# GTF is required for final feature renaming\n",
    "REF_GTF = './iso_ref/Mus_musculus.GRCm39.109.sorted.gtf'\n",
    "\n",
    "# 4. Barcode Whitelist\n",
    "# Path to the list of valid cellular barcodes (from a seeksoultools fast run or any other list)\n",
    "# Note: Use the 'raw' list if you intend to use SoupX downstream.\n",
    "BARCODE_WHITELIST_GZ = f'path/to/seeksoultools-fast-output/step3/{matrix_type}_feature_bc_matrix/barcodes.tsv.gz'\n",
    "\n",
    "# 5. Library Geometry (SeekOne DD)\n",
    "# Geometry: Barcode (17bp) + UMI (12bp) located at the 5' end of Read 1.\n",
    "BARCODE_LEN = 17\n",
    "UMI_LEN = 12\n",
    "READ_ORIENTATION = \"5\" # Barcodes are at the beginning of the read\n",
    "LIB_TYPE = \"ISR\"       # Inward Stranded Reverse (Read 2 matches transcript sense)\n",
    "\n",
    "# 6. System Resources\n",
    "CPU_THREADS = 8\n",
    "\n",
    "# Directory Initialization\n",
    "SALMON_DIR = os.path.join(OUTPUT_ROOT, \"salmon\")\n",
    "FINAL_MATRIX_DIR = os.path.join(OUTPUT_ROOT, \"raw_isoform_matrix\")\n",
    "\n",
    "os.makedirs(SALMON_DIR, exist_ok=True)\n",
    "os.makedirs(FINAL_MATRIX_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Configuration loaded.\")\n",
    "print(f\"Output Directory: {os.path.abspath(OUTPUT_ROOT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68494ce3-1d56-4c30-bbd7-fb4e771dc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {message}\")\n",
    "\n",
    "def ensure_salmon_installed():\n",
    "    \"\"\"\n",
    "    Robustly checks for or installs Salmon. \n",
    "    Handles Linux servers and macOS nuances automatically.\n",
    "    \"\"\"\n",
    "    # 1. Check existing installation\n",
    "    salmon_exec = shutil.which(\"salmon\")\n",
    "    if salmon_exec:\n",
    "        try:\n",
    "            res = subprocess.run([salmon_exec, \"--version\"], capture_output=True, text=True)\n",
    "            log(f\"System Salmon detected: {res.stdout.strip()}\")\n",
    "            return salmon_exec\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    log(\"Salmon not found in PATH. Initiating installation routine...\")\n",
    "    system_os = platform.system()\n",
    "    \n",
    "    # STRATEGY A: CONDA (Cross-Platform)\n",
    "    if shutil.which(\"conda\"):\n",
    "        log(\"Attempting installation via Conda (ensuring conda-forge for dependencies)...\")\n",
    "        try:\n",
    "            # Explicitly adding conda-forge fixes libiconv issues on Mac M1/M2\n",
    "            cmd = [\"conda\", \"install\", \"-c\", \"conda-forge\", \"-c\", \"bioconda\", \"salmon>=1.10.0\", \"-y\"]\n",
    "            subprocess.run(cmd, check=True)\n",
    "            \n",
    "            salmon_exec = shutil.which(\"salmon\")\n",
    "            if salmon_exec:\n",
    "                log(f\"Salmon installed via Conda at: {salmon_exec}\")\n",
    "                return salmon_exec\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            log(f\"Conda installation failed: {e}\")\n",
    "\n",
    "    # STRATEGY B: LINUX BINARY DOWNLOAD (Linux Only)\n",
    "    if system_os == \"Linux\":\n",
    "        log(\"Downloading pre-compiled binary from GitHub...\")\n",
    "        url = \"https://github.com/COMBINE-lab/salmon/releases/download/v1.10.0/salmon-1.10.0_linux_x86_64.tar.gz\"\n",
    "        filename = \"salmon-1.10.0_linux_x86_64.tar.gz\"\n",
    "        folder = \"salmon-1.10.0_linux_x86_64\"\n",
    "        \n",
    "        # Use wget or curl\n",
    "        if shutil.which(\"wget\"):\n",
    "            subprocess.run([\"wget\", \"-q\", \"-O\", filename, url], check=True)\n",
    "        else:\n",
    "            subprocess.run([\"curl\", \"-L\", \"-o\", filename, url], check=True)\n",
    "            \n",
    "        subprocess.run([\"tar\", \"xzf\", filename], check=True)\n",
    "        local_bin = os.path.abspath(f\"{folder}/bin/salmon\")\n",
    "        \n",
    "        if os.path.exists(local_bin):\n",
    "            log(f\"Salmon installed locally at: {local_bin}\")\n",
    "            return local_bin\n",
    "\n",
    "    # STRATEGY C: HOMEBREW (macOS Only)\n",
    "    if system_os == \"Darwin\" and shutil.which(\"brew\"):\n",
    "        log(\"Attempting installation via Homebrew...\")\n",
    "        try:\n",
    "            subprocess.run([\"brew\", \"tap\", \"brewsci/bio\"], check=True)\n",
    "            subprocess.run([\"brew\", \"install\", \"salmon\"], check=True)\n",
    "            salmon_exec = shutil.which(\"salmon\")\n",
    "            if salmon_exec:\n",
    "                log(\"Salmon installed via Homebrew.\")\n",
    "                return salmon_exec\n",
    "        except subprocess.CalledProcessError:\n",
    "            pass\n",
    "\n",
    "    raise FileNotFoundError(\"CRITICAL: Failed to install Salmon. Please install 'salmon' manually in your terminal.\")\n",
    "\n",
    "# Initialize\n",
    "salmon_path = ensure_salmon_installed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a0f23-8922-46bb-a182-00d84e8fdb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_DIR = os.path.join(SALMON_DIR, \"salmon_index\")\n",
    "TGMAP_FILE = os.path.join(SALMON_DIR, \"isoform_tgmap.tsv\")\n",
    "\n",
    "# A. Build Index\n",
    "if os.path.exists(os.path.join(INDEX_DIR, \"pos.bin\")):\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Existing Salmon index found. Skipping build.\")\n",
    "else:\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Building Salmon index (this may take time)...\")\n",
    "    cmd = [\n",
    "        salmon_path, \"index\",\n",
    "        \"-t\", REF_FASTA,\n",
    "        \"-i\", INDEX_DIR,\n",
    "        \"-p\", str(CPU_THREADS)\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Indexing complete.\")\n",
    "\n",
    "# B. Generate tgMap (Identity Mapping)\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Generating transcript-to-gene map from FASTA headers...\")\n",
    "\n",
    "tx_count = 0\n",
    "open_func = gzip.open if REF_FASTA.endswith('.gz') else open\n",
    "mode = 'rt' if REF_FASTA.endswith('.gz') else 'r'\n",
    "\n",
    "with open_func(REF_FASTA, mode) as f_in, open(TGMAP_FILE, 'w') as f_out:\n",
    "    for line in f_in:\n",
    "        if line.startswith(\">\"):\n",
    "            # Extract ID (e.g., >ENSMUST000...2 cdna...) -> ENSMUST000...2\n",
    "            # We map ID -> ID to force Alevin to quantify isoforms individually.\n",
    "            tx_id = line.split()[0].replace(\">\", \"\")\n",
    "            f_out.write(f\"{tx_id}\\t{tx_id}\\n\")\n",
    "            tx_count += 1\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] tgMap generated containing {tx_count} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9895c-adc2-4120-b08a-541e4e81f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITELIST_TSV = os.path.join(SALMON_DIR, \"whitelist.tsv\")\n",
    "\n",
    "if os.path.exists(BARCODE_WHITELIST_GZ):\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Decompressing whitelist: {os.path.basename(BARCODE_WHITELIST_GZ)}\")\n",
    "    with gzip.open(BARCODE_WHITELIST_GZ, 'rb') as f_in, open(WHITELIST_TSV, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Whitelist not found at: {BARCODE_WHITELIST_GZ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122040a8-6861-450a-8a94-0e562e199da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALEVIN_OUT_DIR = os.path.join(SALMON_DIR, \"alevin_output\")\n",
    "\n",
    "# Cleanup previous runs to ensure data integrity\n",
    "if os.path.exists(ALEVIN_OUT_DIR):\n",
    "    shutil.rmtree(ALEVIN_OUT_DIR)\n",
    "\n",
    "cmd = [\n",
    "    salmon_path, \"alevin\",\n",
    "    \"-l\", LIB_TYPE,             # Library type (ISR)\n",
    "    \"-1\", FASTQ_R1,             # Read 1 (Barcodes)\n",
    "    \"-2\", FASTQ_R2,             # Read 2 (Biological)\n",
    "    \"-i\", INDEX_DIR,            # Index\n",
    "    \"-p\", str(CPU_THREADS),\n",
    "    \"-o\", ALEVIN_OUT_DIR,\n",
    "    \"--tgMap\", TGMAP_FILE,\n",
    "    \"--whitelist\", WHITELIST_TSV,\n",
    "    \"--dumpMtx\",                # Export sparse matrix\n",
    "    # Explicit Geometry Definition\n",
    "    \"--barcodeLength\", str(BARCODE_LEN),\n",
    "    \"--umiLength\", str(UMI_LEN),\n",
    "    \"--end\", READ_ORIENTATION\n",
    "]\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Starting Salmon Alevin Quantification...\")\n",
    "print(f\"Command execution: {' '.join(cmd)}\\n\")\n",
    "\n",
    "# Execute with real-time log streaming\n",
    "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "# Stream logs\n",
    "for line in process.stdout:\n",
    "    print(line, end=\"\")\n",
    "\n",
    "process.wait()\n",
    "\n",
    "if process.returncode == 0:\n",
    "    print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Quantification finished successfully.\")\n",
    "else:\n",
    "    raise RuntimeError(f\"Salmon Alevin terminated with error code {process.returncode}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8ceb3-3bd9-4ecc-8ad1-df56d3c55dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Processing output matrix and annotations...\")\n",
    "\n",
    "# 1. Load Annotations (GTF)\n",
    "id_to_readable = {}\n",
    "open_func = gzip.open if REF_GTF.endswith('.gz') else open\n",
    "mode = 'rt' if REF_GTF.endswith('.gz') else 'r'\n",
    "\n",
    "with open_func(REF_GTF, mode) as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\") or \"\\ttranscript\\t\" not in line: \n",
    "            continue\n",
    "        attrs = {}\n",
    "        for item in line.strip().split(\"\\t\")[8].split(\";\"):\n",
    "            if not item.strip(): continue\n",
    "            parts = item.strip().split(\" \")\n",
    "            if len(parts) >= 2:\n",
    "                key = parts[0].strip()\n",
    "                val = parts[1].replace('\"', '').replace(';', '').strip()\n",
    "                attrs[key] = val\n",
    "        tx_id = attrs.get(\"transcript_id\")\n",
    "        tx_name = attrs.get(\"transcript_name\", tx_id)\n",
    "        if tx_id:\n",
    "            id_to_readable[tx_id.split('.')[0]] = tx_name\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Loaded annotations for {len(id_to_readable)} transcripts.\")\n",
    "\n",
    "# 2. Locate Files\n",
    "found_matrix_path = None\n",
    "real_source_dir = None\n",
    "is_matrix_gzipped = False\n",
    "\n",
    "for root, dirs, files in os.walk(SALMON_DIR):\n",
    "    if \"quants_mat.mtx.gz\" in files:\n",
    "        found_matrix_path = os.path.join(root, \"quants_mat.mtx.gz\")\n",
    "        real_source_dir = root\n",
    "        is_matrix_gzipped = True\n",
    "        break\n",
    "    elif \"quants_mat.mtx\" in files:\n",
    "        found_matrix_path = os.path.join(root, \"quants_mat.mtx\")\n",
    "        real_source_dir = root\n",
    "        is_matrix_gzipped = False\n",
    "        break\n",
    "\n",
    "if not found_matrix_path:\n",
    "    print(f\"Could not find matrix file in: {SALMON_DIR}\")\n",
    "    raise FileNotFoundError(\"Salmon output matrix not found.\")\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Found matrix: {found_matrix_path}\")\n",
    "\n",
    "# 3. Process & Transpose\n",
    "\n",
    "# A. MATRIX (Needs Transpose: Cells x Genes -> Genes x Cells)\n",
    "target_mtx = os.path.join(FINAL_MATRIX_DIR, \"matrix.mtx.gz\")\n",
    "print(\"   -> Transposing and compressing matrix (Cells x Genes => Genes x Cells)...\")\n",
    "\n",
    "read_mode = 'rt' if is_matrix_gzipped else 'r'\n",
    "open_in = gzip.open if is_matrix_gzipped else open\n",
    "\n",
    "with open_in(found_matrix_path, read_mode) as f_in, gzip.open(target_mtx, 'wt') as f_out:\n",
    "    header_processed = False\n",
    "    for line in f_in:\n",
    "        # Skip comments\n",
    "        if line.startswith('%'):\n",
    "            f_out.write(line)\n",
    "            continue\n",
    "        \n",
    "        parts = line.split()\n",
    "        if not header_processed:\n",
    "            # Dimensions line: Rows Cols NonZeros\n",
    "            # Alevin: Rows=Cells, Cols=Genes\n",
    "            # Seurat wants: Rows=Genes, Cols=Cells\n",
    "            # ACTION: Swap dimensions\n",
    "            if len(parts) >= 2:\n",
    "                rows, cols = parts[0], parts[1]\n",
    "                rest = parts[2:]\n",
    "                f_out.write(f\"{cols} {rows} {' '.join(rest)}\\n\")\n",
    "                header_processed = True\n",
    "        else:\n",
    "            # Data line: Row Col Val\n",
    "            # ACTION: Swap Row and Col indices\n",
    "            if len(parts) >= 3:\n",
    "                r, c = parts[0], parts[1]\n",
    "                val = parts[2]\n",
    "                f_out.write(f\"{c} {r} {val}\\n\")\n",
    "\n",
    "# B. BARCODES (From ROWS.txt)\n",
    "# Alevin Rows = Cells -> Barcodes.tsv\n",
    "rows_src = os.path.join(real_source_dir, \"quants_mat_rows.txt\")\n",
    "if not os.path.exists(rows_src): rows_src += \".gz\"\n",
    "\n",
    "target_barcodes = os.path.join(FINAL_MATRIX_DIR, \"barcodes.tsv.gz\")\n",
    "print(\"   -> Processing barcodes (from rows)...\")\n",
    "\n",
    "if os.path.exists(rows_src):\n",
    "    # Just copy/compress, raw barcodes are usually fine\n",
    "    is_gz = rows_src.endswith('.gz')\n",
    "    with (gzip.open if is_gz else open)(rows_src, 'rb') as f_in, gzip.open(target_barcodes, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "else:\n",
    "    print(\"Warning: Rows file (Barcodes) not found!\")\n",
    "\n",
    "# C. FEATURES (From COLS.txt)\n",
    "# Alevin Cols = Genes -> Features.tsv\n",
    "cols_src = os.path.join(real_source_dir, \"quants_mat_cols.txt\")\n",
    "if not os.path.exists(cols_src): cols_src += \".gz\"\n",
    "\n",
    "target_features = os.path.join(FINAL_MATRIX_DIR, \"features.tsv.gz\")\n",
    "print(\"   -> Processing features (from cols)...\")\n",
    "\n",
    "if os.path.exists(cols_src):\n",
    "    is_gz = cols_src.endswith('.gz')\n",
    "    read_mode = 'rt' if is_gz else 'r'\n",
    "    open_mode = gzip.open if is_gz else open\n",
    "    \n",
    "    with open_mode(cols_src, read_mode) as f_in, gzip.open(target_features, 'wt') as f_out:\n",
    "        for line in f_in:\n",
    "            tx_id_full = line.strip() \n",
    "            tx_id_base = tx_id_full.split('.')[0]\n",
    "            display_name = id_to_readable.get(tx_id_base, tx_id_full)\n",
    "            # Format: ID \\t Name \\t Type\n",
    "            f_out.write(f\"{tx_id_full}\\t{display_name}\\tTranscript Expression\\n\")\n",
    "else:\n",
    "    print(\"Warning: Cols file (Features) not found!\")\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Pipeline finished! Output: {os.path.abspath(FINAL_MATRIX_DIR)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
